{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5289, 17) (39922, 17)\n",
      "(3200, 17) (37900, 17)\n",
      "(2000, 39)\n",
      "(2000, 40)\n",
      "['age' 'balance' 'day' 'duration' 'campaign' 'pdays' 'previous'\n",
      " 'job_admin.' 'job_blue-collar' 'job_entrepreneur' 'job_housemaid'\n",
      " 'job_management' 'job_retired' 'job_self-employed' 'job_services'\n",
      " 'job_student' 'job_technician' 'job_unemployed' 'job_unknown'\n",
      " 'marital_divorced' 'marital_married' 'marital_single' 'education_primary'\n",
      " 'education_secondary' 'education_tertiary' 'education_unknown'\n",
      " 'default_no' 'default_yes' 'housing_no' 'housing_yes' 'loan_no' 'loan_yes'\n",
      " 'contact_cellular' 'contact_telephone' 'contact_unknown'\n",
      " 'poutcome_failure' 'poutcome_other' 'poutcome_success' 'poutcome_unknown'\n",
      " 'month']\n",
      "(3000, 17)\n",
      "(2976, 17)\n",
      "(5976, 16) (5976,)\n",
      "(5976, 40)\n",
      "['age' 'balance' 'day' 'duration' 'campaign' 'pdays' 'previous'\n",
      " 'job_admin.' 'job_blue-collar' 'job_entrepreneur' 'job_housemaid'\n",
      " 'job_management' 'job_retired' 'job_self-employed' 'job_services'\n",
      " 'job_student' 'job_technician' 'job_unemployed' 'job_unknown'\n",
      " 'marital_divorced' 'marital_married' 'marital_single' 'education_primary'\n",
      " 'education_secondary' 'education_tertiary' 'education_unknown'\n",
      " 'default_no' 'default_yes' 'housing_no' 'housing_yes' 'loan_no' 'loan_yes'\n",
      " 'contact_cellular' 'contact_telephone' 'contact_unknown'\n",
      " 'poutcome_failure' 'poutcome_other' 'poutcome_success' 'poutcome_unknown'\n",
      " 'month']\n",
      "(5976, 40)\n",
      "(3000, 17)\n",
      "(2880, 17)\n",
      "(5880, 16) (5880,)\n",
      "(5880, 40)\n",
      "(5880, 40)\n",
      "(3000, 17)\n",
      "(2976, 17)\n",
      "(5976, 16) (5976,)\n",
      "(5976, 40)\n",
      "(3000, 17)\n",
      "(2976, 17)\n",
      "(5976, 16) (5976,)\n",
      "(5976, 40)\n",
      "(3000, 17)\n",
      "(2976, 17)\n",
      "(5976, 16) (5976,)\n",
      "(5976, 40)\n",
      "(3000, 17)\n",
      "(2976, 17)\n",
      "(5976, 16) (5976,)\n",
      "(5976, 40)\n",
      "(4740, 17)\n",
      "(2976, 17)\n",
      "(7716, 16) (7716,)\n",
      "(7716, 40)\n",
      "(1000, 17) (1000, 17)\n",
      "(2000, 17)\n",
      "(2000, 16)\n",
      "(2000, 40)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(2000, 7)\n",
      "   0  0  0  0  0  0  0\n",
      "0  1  1  1  1  1  1  1\n",
      "1  1  1  0  0  1  1  0\n",
      "2  1  1  1  1  1  1  0\n",
      "3  1  1  0  0  1  0  1\n",
      "4  1  1  1  1  1  1  1\n",
      "(2000,)\n",
      "61.75\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score, classification_report\n",
    "\n",
    "bankData = pd.read_csv('bank-full.csv',delimiter=';')\n",
    "\n",
    "#Checking skewness of class\n",
    "bankData.y.value_counts()\n",
    "\n",
    "#Now that the class is highly skewed, first dividing the data based on their class.\n",
    "XYes = bankData[bankData['y'] == 'yes']\n",
    "XNo = bankData[bankData['y'] == 'no']\n",
    "print XYes.shape, XNo.shape\n",
    "\n",
    "#Now separating 1000 values for stacking from both the classes, and , 1000 values for test.\n",
    "XYesStacking = XYes.iloc[4289:5289] \n",
    "XNoStacking = XNo.iloc[38922:39922]\n",
    "XYesTest = XYes.iloc[3289:4289] \n",
    "XNoTest = XNo.iloc[37922:38922]  \n",
    "\n",
    "# Separating XYes and XNo for first layer of classfiers.\n",
    "\n",
    "XYesFirst = XYes.iloc[:3200]\n",
    "XNoFirst = XNo.iloc[:37900]\n",
    "print XYesFirst.shape, XNoFirst.shape\n",
    "\n",
    "# XTest ---> 1000 Yes and 1000 No\n",
    "\n",
    "Z = [XYesTest,XNoTest] \n",
    "Z = pd.concat(Z)\n",
    "XTest = Z.drop(['y'],axis=1)\n",
    "#label encoder for month\n",
    "Month = XTest['month']\n",
    "XTest = XTest.drop(['month'],axis=1)\n",
    "XTest = pd.get_dummies(XTest, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False)\n",
    "print XTest.shape\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le = le.fit(Month)\n",
    "Month = le.transform(Month)\n",
    "XTest['month'] = Month\n",
    "\n",
    "print XTest.shape\n",
    "print XTest.columns.values\n",
    "\n",
    "YTestFinal = Z['y']\n",
    "mapping = {'no':0,'yes':1}\n",
    "YTestFinal=YTestFinal.apply(lambda x :mapping[x])\n",
    "\n",
    "# First Model\n",
    "\n",
    "XNoOne = XNoFirst.iloc[:5000]\n",
    "XNoOne = XNoOne.sample(frac=0.6)\n",
    "print XNoOne.shape\n",
    "XYesOne = XYesFirst.sample(frac=0.93)\n",
    "print XYesOne.shape\n",
    "\n",
    "XOne = [XNoOne,XYesOne]\n",
    "XOne = pd.concat(XOne)\n",
    "\n",
    "XTrainOne = XOne.drop(['y'],axis=1)\n",
    "YTrainOne = XOne['y']\n",
    "print XTrainOne.shape, YTrainOne.shape\n",
    "\n",
    "#label encoder for month\n",
    "Month = XTrainOne['month']\n",
    "XTrainOne = XTrainOne.drop(['month'],axis=1)\n",
    "XTrainOne = pd.get_dummies(XTrainOne, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le = le.fit(Month)\n",
    "Month = le.transform(Month)\n",
    "XTrainOne['month'] = Month\n",
    "\n",
    "#XTrainOne, XTestOne, YTrainOne, YTestOne = train_test_split(XTrainOne,YTrainOne, test_size=0.2, random_state=42)\n",
    "print XTrainOne.shape\n",
    "print XTrainOne.columns.values\n",
    "\n",
    "mapping = {'no':0,'yes':1}\n",
    "YTrainOne=YTrainOne.apply(lambda x :mapping[x])\n",
    "#YTestOne=YTestOne.apply(lambda x :mapping[x])\n",
    "\n",
    "\n",
    "parameters = {'n_estimators':[3,4,5,6,7,8,9,10,100], 'criterion':['gini','entropy'], 'max_depth':[1,2,3,4,5], 'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1,5,8]}\n",
    "\n",
    "kfold=10\n",
    "rfc1=RandomForestClassifier(random_state=42)\n",
    "\n",
    "nIters=10\n",
    "clfRfc1 = GridSearchCV(rfc1, parameters,cv=kfold)\n",
    "clfRfc1.fit(XTrainOne , YTrainOne)\n",
    "rfc1 = clfRfc1.best_estimator_\n",
    "\n",
    "print XTrainOne.shape\n",
    "\n",
    "rfc1.fit(XTrainOne , YTrainOne)\n",
    "YPredictOne = rfc1.predict(XTest)\n",
    "accuracy_score(YTestFinal,YPredictOne)\n",
    "\n",
    "# Second Model\n",
    "\n",
    "XNoTwo = XNoFirst.iloc[5000:10000]\n",
    "XNoTwo = XNoTwo.sample(frac=0.6)\n",
    "print XNoTwo.shape\n",
    "XYesTwo = XYesFirst.sample(frac=0.9)\n",
    "print XYesTwo.shape\n",
    "\n",
    "XTwo = [XNoTwo,XYesTwo]\n",
    "XTwo = pd.concat(XTwo)\n",
    "\n",
    "XTrainTwo = XTwo.drop(['y'],axis=1)\n",
    "YTrainTwo = XTwo['y']\n",
    "print XTrainTwo.shape, YTrainTwo.shape\n",
    "#label encoder for month\n",
    "Month = XTrainTwo['month']\n",
    "XTrainTwo = XTrainTwo.drop(['month'],axis=1)\n",
    "XTrainTwo = pd.get_dummies(XTrainTwo, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le = le.fit(Month)\n",
    "Month = le.transform(Month)\n",
    "XTrainTwo['month'] = Month\n",
    "\n",
    "print XTrainTwo.shape\n",
    "\n",
    "#XTrainTwo, XTestTwo, YTrainTwo, YTestTwo = train_test_split(XTrainTwo,YTrainTwo, test_size=0.2, random_state=42)\n",
    "\n",
    "mapping = {'no':0,'yes':1}\n",
    "YTrainTwo=YTrainTwo.apply(lambda x :mapping[x])\n",
    "#YTestTwo=YTestTwo.apply(lambda x :mapping[x])\n",
    "\n",
    "parameters = {'n_estimators':[3,4,5,6,7,8,9,10,100], 'criterion':['gini','entropy'], 'max_depth':[1,2,3,4,5], 'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1,5,8]}\n",
    "\n",
    "kfold=10\n",
    "rfc2=RandomForestClassifier(random_state=42)\n",
    "\n",
    "nIters=10\n",
    "clfRfc2 = GridSearchCV(rfc2, parameters,cv=kfold)\n",
    "clfRfc2.fit(XTrainTwo , YTrainTwo)\n",
    "rfc2 = clfRfc2.best_estimator_\n",
    "\n",
    "print XTrainTwo.shape\n",
    "\n",
    "rfc2.fit(XTrainTwo , YTrainTwo)\n",
    "YPredictTwo = rfc2.predict(XTest)\n",
    "accuracy_score(YTestFinal,YPredictTwo)*100\n",
    "# Third Model\n",
    "\n",
    "XNoThree = XNoFirst.iloc[10000:15000]\n",
    "XNoThree = XNoThree.sample(frac=0.6)\n",
    "print XNoThree.shape\n",
    "XYesThree = XYesFirst.sample(frac=0.93)\n",
    "print XYesThree.shape\n",
    "\n",
    "XThree = [XNoThree,XYesThree]\n",
    "XThree = pd.concat(XThree)\n",
    "\n",
    "XTrainThree = XThree.drop(['y'],axis=1)\n",
    "YTrainThree = XThree['y']\n",
    "print XTrainThree.shape, YTrainThree.shape\n",
    "#label encoder for month\n",
    "Month = XTrainThree['month']\n",
    "XTrainThree = XTrainThree.drop(['month'],axis=1)\n",
    "XTrainThree = pd.get_dummies(XTrainThree, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le = le.fit(Month)\n",
    "Month = le.transform(Month)\n",
    "XTrainThree['month'] = Month\n",
    "#XTrainThree, XTestThree, YTrainThree, YTestThree = train_test_split(XTrainThree,YTrainThree, test_size=0.2, random_state=42)\n",
    "print XTrainThree.shape\n",
    "\n",
    "mapping = {'no':0,'yes':1}\n",
    "YTrainThree=YTrainThree.apply(lambda x :mapping[x])\n",
    "#YTestThree=YTestThree.apply(lambda x :mapping[x])\n",
    "\n",
    "parameters = {'n_estimators':[3,4,5,6,7,8,9,10,100], 'criterion':['gini','entropy'], 'max_depth':[1,2,3,4,5], 'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1,5,8]}\n",
    "kfold=10\n",
    "rfc3=RandomForestClassifier(random_state=42)\n",
    "\n",
    "nIters=10\n",
    "clfRfc3 = GridSearchCV(rfc3, parameters,cv=kfold)\n",
    "clfRfc3.fit(XTrainThree , YTrainThree)\n",
    "rfc3 = clfRfc3.best_estimator_\n",
    "\n",
    "rfc3.fit(XTrainThree , YTrainThree)\n",
    "YPredictThree = rfc3.predict(XTest)\n",
    "accuracy_score(YTestFinal,YPredictThree)*100\n",
    "\n",
    "# Fourth Model\n",
    "\n",
    "XNoFour = XNoFirst.iloc[15000:20000]\n",
    "XNoFour = XNoFour.sample(frac=0.6)\n",
    "print XNoFour.shape\n",
    "XYesFour = XYesFirst.sample(frac=0.93)\n",
    "print XYesFour.shape\n",
    "\n",
    "XFour = [XNoFour,XYesFour]\n",
    "XFour = pd.concat(XFour)\n",
    "\n",
    "XTrainFour = XFour.drop(['y'],axis=1)\n",
    "YTrainFour = XFour['y']\n",
    "print XTrainFour.shape, YTrainFour.shape\n",
    "#label encoder for month\n",
    "Month = XTrainFour['month']\n",
    "XTrainFour = XTrainFour.drop(['month'],axis=1)\n",
    "XTrainFour = pd.get_dummies(XTrainFour, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le = le.fit(Month)\n",
    "Month = le.transform(Month)\n",
    "XTrainFour['month'] = Month\n",
    "print XTrainFour.shape\n",
    "\n",
    "#XTrainFour, XTestFour, YTrainFour, YTestFour = train_test_split(XTrainFour,YTrainFour, test_size=0.2, random_state=42)\n",
    "\n",
    "mapping = {'no':0,'yes':1}\n",
    "YTrainFour=YTrainFour.apply(lambda x :mapping[x])\n",
    "#YTestFour=YTestFour.apply(lambda x :mapping[x])\n",
    "\n",
    "parameters = {'n_estimators':[3,4,5,6,7,8,9,10,100], 'criterion':['gini','entropy'], 'max_depth':[1,2,3,4,5], 'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1,5,8]}\n",
    "kfold=10\n",
    "rfc4=RandomForestClassifier(random_state=42)\n",
    "\n",
    "nIters=10\n",
    "clfRfc4 = GridSearchCV(rfc4, parameters,cv=kfold)\n",
    "clfRfc4.fit(XTrainFour , YTrainFour)\n",
    "rfc4 = clfRfc4.best_estimator_\n",
    "\n",
    "rfc4.fit(XTrainFour , YTrainFour)\n",
    "YPredictFour= rfc4.predict(XTest)\n",
    "accuracy_score(YTestFinal,YPredictFour)*100\n",
    "# Fifth Model\n",
    "\n",
    "XNoFive = XNoFirst.iloc[20000:25000]\n",
    "XNoFive = XNoFive.sample(frac=0.6)\n",
    "print XNoFive.shape\n",
    "XYesFive = XYesFirst.sample(frac=0.93)\n",
    "print XYesFive.shape\n",
    "\n",
    "XFive = [XNoFive,XYesFive]\n",
    "XFive = pd.concat(XFive)\n",
    "\n",
    "XTrainFive = XFive.drop(['y'],axis=1)\n",
    "YTrainFive = XFive['y']\n",
    "print XTrainFive.shape, YTrainFive.shape\n",
    "#label encoder for month\n",
    "Month = XTrainFive['month']\n",
    "XTrainFive = XTrainFive.drop(['month'],axis=1)\n",
    "XTrainFive = pd.get_dummies(XTrainFive, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le = le.fit(Month)\n",
    "Month = le.transform(Month)\n",
    "XTrainFive['month'] = Month\n",
    "print XTrainFive.shape\n",
    "#XTrainFive, XTestFive, YTrainFive, YTestFive = train_test_split(XTrainFive,YTrainFive, test_size=0.2, random_state=42)\n",
    "\n",
    "mapping = {'no':0,'yes':1}\n",
    "YTrainFive=YTrainFive.apply(lambda x :mapping[x])\n",
    "#YTestFive=YTestFive.apply(lambda x :mapping[x])\n",
    "\n",
    "parameters = {'n_estimators':[3,4,5,6,7,8,9,10,100], 'criterion':['gini','entropy'], 'max_depth':[1,2,3,4,5], 'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1,5,8]}\n",
    "kfold=10\n",
    "rfc5=RandomForestClassifier(random_state=42)\n",
    "\n",
    "nIters=10\n",
    "clfRfc5 = GridSearchCV(rfc5, parameters,cv=kfold)\n",
    "clfRfc5.fit(XTrainFive , YTrainFive)\n",
    "rfc5 = clfRfc5.best_estimator_\n",
    "\n",
    "rfc5.fit(XTrainFive , YTrainFive)\n",
    "YPredictFive = rfc5.predict(XTest)\n",
    "accuracy_score(YTestFinal,YPredictFive)*100\n",
    "\n",
    "# Sixth Model\n",
    "\n",
    "XNoSix = XNoFirst.iloc[25000:30000]\n",
    "XNoSix = XNoSix.sample(frac=0.6)\n",
    "print XNoSix.shape\n",
    "XYesSix = XYesFirst.sample(frac=0.93)\n",
    "print XYesSix.shape\n",
    "\n",
    "XSix = [XNoSix,XYesSix]\n",
    "XSix = pd.concat(XSix)\n",
    "\n",
    "XTrainSix = XSix.drop(['y'],axis=1)\n",
    "YTrainSix = XSix['y']\n",
    "print XTrainSix.shape, YTrainSix.shape\n",
    "#label encoder for month\n",
    "Month = XTrainSix['month']\n",
    "XTrainSix = XTrainSix.drop(['month'],axis=1)\n",
    "XTrainSix = pd.get_dummies(XTrainSix, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le = le.fit(Month)\n",
    "Month = le.transform(Month)\n",
    "XTrainSix['month'] = Month\n",
    "print XTrainSix.shape\n",
    "#XTrainSix, XTestSix, YTrainSix, YTestSix = train_test_split(XTrainSix,YTrainSix, test_size=0.2, random_state=42)\n",
    "\n",
    "mapping = {'no':0,'yes':1}\n",
    "YTrainSix=YTrainSix.apply(lambda x :mapping[x])\n",
    "#YTestSix=YTestSix.apply(lambda x :mapping[x])\n",
    "\n",
    "parameters = {'n_estimators':[3,4,5,6,7,8,9,10,100], 'criterion':['gini','entropy'], 'max_depth':[1,2,3,4,5], 'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1,5,8]}\n",
    "kfold=10\n",
    "rfc6=RandomForestClassifier(random_state=42)\n",
    "\n",
    "nIters=10\n",
    "clfRfc6 = GridSearchCV(rfc6, parameters,cv=kfold)\n",
    "clfRfc6.fit(XTrainSix , YTrainSix)\n",
    "rfc6 = clfRfc6.best_estimator_\n",
    "\n",
    "rfc6.fit(XTrainSix , YTrainSix)\n",
    "YPredictSix = rfc6.predict(XTest)\n",
    "accuracy_score(YTestFinal,YPredictSix)*100\n",
    "\n",
    "# Seventh Model\n",
    "\n",
    "XNoSeven = XNoFirst.iloc[30000:37900]\n",
    "XNoSeven = XNoSeven.sample(frac=0.6)\n",
    "print XNoSeven.shape\n",
    "XYesSeven = XYesFirst.sample(frac=0.93)\n",
    "print XYesSeven.shape\n",
    "\n",
    "XSeven = [XNoSeven,XYesSeven]\n",
    "XSeven = pd.concat(XSeven)\n",
    "\n",
    "XTrainSeven = XSeven.drop(['y'],axis=1)\n",
    "YTrainSeven = XSeven['y']\n",
    "print XTrainSeven.shape, YTrainSeven.shape\n",
    "#label encoder for month-------\n",
    "Month = XTrainSeven['month']\n",
    "XTrainSeven = XTrainSeven.drop(['month'],axis=1)\n",
    "XTrainSeven = pd.get_dummies(XTrainSeven, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le = le.fit(Month)\n",
    "Month = le.transform(Month)\n",
    "XTrainSeven['month'] = Month\n",
    "\n",
    "print XTrainSeven.shape\n",
    "#XTrainSeven, XTestSeven, YTrainSeven, YTestSeven = train_test_split(XTrainSeven,YTrainSeven, test_size=0.2, random_state=42)\n",
    "\n",
    "mapping = {'no':0,'yes':1}\n",
    "YTrainSeven=YTrainSeven.apply(lambda x :mapping[x])\n",
    "#YTestSeven=YTestSeven.apply(lambda x :mapping[x])\n",
    "\n",
    "parameters = {'n_estimators':[3,4,5,6,7,8,9,10,100], 'criterion':['gini','entropy'], 'max_depth':[1,2,3,4,5], 'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1,5,8]}\n",
    "kfold=10\n",
    "rfc7=RandomForestClassifier(random_state=42)\n",
    "\n",
    "nIters=10\n",
    "clfRfc7 = GridSearchCV(rfc7, parameters,cv=kfold)\n",
    "clfRfc7.fit(XTrainSeven , YTrainSeven)\n",
    "rfc7 = clfRfc7.best_estimator_\n",
    "\n",
    "rfc7.fit(XTrainSeven , YTrainSeven)\n",
    "YPredictSeven = rfc7.predict(XTest)\n",
    "accuracy_score(YTestFinal,YPredictSeven)*100\n",
    "\n",
    "#Stacking ---> 1000 Yes and 1000 No\n",
    "\n",
    "X = [XYesStacking,XNoStacking] \n",
    "print XYesStacking.shape, XNoStacking.shape\n",
    "X = pd.concat(X)\n",
    "print X.shape\n",
    "XStacked = X.drop(['y'],axis=1)\n",
    "print XStacked.shape\n",
    "#label encoder for month\n",
    "Month = XStacked['month']\n",
    "XStacked = XStacked.drop(['month'],axis=1)\n",
    "XStacked = pd.get_dummies(XStacked, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le = le.fit(Month)\n",
    "Month = le.transform(Month)\n",
    "XStacked['month'] = Month\n",
    "print XStacked.shape\n",
    "\n",
    "\n",
    "\n",
    "F1 = rfc1.predict(XStacked)\n",
    "F1 = pd.DataFrame(F1)\n",
    "F2 = rfc2.predict(XStacked)\n",
    "F2 = pd.DataFrame(F2)\n",
    "F3 = rfc3.predict(XStacked)\n",
    "F3 = pd.DataFrame(F3)\n",
    "F4 = rfc4.predict(XStacked)\n",
    "F4 = pd.DataFrame(F4)\n",
    "F5 = rfc5.predict(XStacked)\n",
    "F5 = pd.DataFrame(F5)\n",
    "F6 = rfc6.predict(XStacked)\n",
    "F6 = pd.DataFrame(F6)\n",
    "F7 = rfc7.predict(XStacked)\n",
    "F7 = pd.DataFrame(F7)\n",
    "\n",
    "print type(F1)\n",
    "\n",
    "#print F1.shape, F2.shape, F3.shape, F4.shape, F5.shape, F6.shape, F7.shape\n",
    "\n",
    "Features = [F1,F2,F3,F4,F5,F6,F7]\n",
    "XTrainEnsemble = pd.concat(Features, axis=1)\n",
    "print XTrainEnsemble.shape\n",
    "print XTrainEnsemble.head()\n",
    "\n",
    "\n",
    "YTrainEnsemble = X['y']\n",
    "print YTrainEnsemble.shape\n",
    "mapping = {'no':0,'yes':1}\n",
    "YTrainEnsemble=YTrainEnsemble.apply(lambda x :mapping[x])\n",
    "\n",
    "parameters = {'n_estimators':[3,4,5,6,7,8,9,10,100], 'criterion':['gini','entropy'], 'max_depth':[1,2,3,4,5], 'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1,5,8]}\n",
    "kfold=10\n",
    "finalCLF=RandomForestClassifier(random_state=42)\n",
    "\n",
    "nIters=10\n",
    "clfRfc = GridSearchCV(finalCLF, parameters,cv=kfold)\n",
    "clfRfc.fit(XTrainEnsemble , YTrainEnsemble)\n",
    "finalCLF = clfRfc.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "finalCLF = finalCLF.fit(XTrainEnsemble,YTrainEnsemble)\n",
    "# Preparing XTest by passing through every model\n",
    "\n",
    "\n",
    "\n",
    "F11 = rfc1.predict(XTest)\n",
    "F11 = pd.DataFrame(F11)\n",
    "F22 = rfc2.predict(XTest)\n",
    "F22 = pd.DataFrame(F22)\n",
    "F33 = rfc3.predict(XTest)\n",
    "F33 = pd.DataFrame(F33)\n",
    "F44 = rfc4.predict(XTest)\n",
    "F44 = pd.DataFrame(F44)\n",
    "F55 = rfc5.predict(XTest)\n",
    "F55 = pd.DataFrame(F55)\n",
    "F66 = rfc6.predict(XTest)\n",
    "F66 = pd.DataFrame(F66)\n",
    "F77 = rfc7.predict(XTest)\n",
    "F77 = pd.DataFrame(F77)\n",
    "\n",
    "FeaturesTest = [F11,F22,F33,F44,F55,F66,F77]\n",
    "XTestFinal = pd.concat(FeaturesTest, axis=1)\n",
    "\n",
    "YPredicted = finalCLF.predict(XTestFinal)\n",
    "print accuracy_score(YTestFinal, YPredicted)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
